{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14c9e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1520 576\n",
      "1540 624\n",
      "348 726\n",
      "372 686\n",
      "313 669\n",
      "262 664\n",
      "267 688\n",
      "212 636\n",
      "194 588\n",
      "211 605\n",
      "260 597\n",
      "328 594\n",
      "539 712\n",
      "467 611\n",
      "504 639\n",
      "489 619\n",
      "418 593\n",
      "305 641\n",
      "314 634\n",
      "262 631\n",
      "312 605\n",
      "483 613\n",
      "425 628\n",
      "496 616\n",
      "505 629\n",
      "481 620\n",
      "488 618\n",
      "487 601\n",
      "480 587\n",
      "490 601\n",
      "524 623\n",
      "234 689\n",
      "1727 708\n",
      "1753 724\n",
      "1801 759\n",
      "1847 834\n",
      "1872 890\n",
      "1849 892\n",
      "1349 857\n",
      "1770 829\n",
      "1315 963\n",
      "1322 955\n",
      "1301 966\n",
      "1333 953\n",
      "1303 947\n",
      "1012 781\n",
      "941 588\n",
      "1291 578\n",
      "1262 538\n",
      "1223 535\n",
      "1148 495\n",
      "1135 486\n",
      "1076 496\n",
      "1053 507\n",
      "1015 520\n",
      "1016 533\n",
      "1027 547\n",
      "1051 549\n",
      "1078 551\n",
      "1125 563\n",
      "1154 572\n",
      "1165 576\n",
      "1189 589\n",
      "1159 582\n",
      "1099 563\n",
      "995 566\n",
      "963 562\n",
      "935 559\n",
      "905 548\n",
      "880 538\n",
      "866 536\n",
      "855 550\n",
      "856 551\n",
      "850 561\n",
      "844 586\n",
      "843 595\n",
      "850 626\n",
      "858 670\n",
      "878 698\n",
      "914 742\n",
      "963 751\n",
      "1051 786\n",
      "1065 797\n",
      "1064 797\n",
      "1068 804\n",
      "1071 801\n",
      "1062 802\n",
      "1047 803\n",
      "1056 786\n",
      "1053 782\n",
      "1054 781\n",
      "1046 794\n",
      "1033 797\n",
      "1034 789\n",
      "1029 790\n",
      "1038 788\n",
      "1033 851\n",
      "1006 833\n",
      "965 768\n",
      "1046 749\n",
      "1123 710\n",
      "1176 734\n",
      "1187 767\n",
      "1211 827\n",
      "1225 864\n",
      "1219 866\n",
      "1221 867\n",
      "1227 851\n",
      "1233 852\n",
      "1229 854\n",
      "1216 858\n",
      "1229 850\n",
      "1234 849\n",
      "1238 853\n",
      "1234 856\n",
      "1218 836\n",
      "1202 796\n",
      "1167 784\n",
      "1163 741\n",
      "1151 733\n",
      "1144 732\n",
      "1148 725\n",
      "1128 712\n",
      "1101 689\n",
      "1116 685\n",
      "1122 717\n",
      "1185 729\n",
      "1110 697\n",
      "1132 694\n",
      "1147 716\n",
      "1179 777\n",
      "1313 785\n",
      "1333 597\n",
      "1270 545\n",
      "1218 528\n",
      "1215 530\n",
      "1346 551\n",
      "1353 548\n",
      "1233 541\n",
      "1148 527\n",
      "1129 522\n",
      "1107 516\n",
      "1053 510\n",
      "989 532\n",
      "900 538\n",
      "907 542\n",
      "912 544\n",
      "903 565\n",
      "890 588\n",
      "894 588\n",
      "895 588\n",
      "902 601\n",
      "901 588\n",
      "898 583\n",
      "893 587\n",
      "910 588\n",
      "908 594\n",
      "904 593\n",
      "906 592\n",
      "921 617\n",
      "949 686\n",
      "972 729\n",
      "966 727\n",
      "960 713\n",
      "966 715\n",
      "962 667\n",
      "877 355\n",
      "842 346\n",
      "844 328\n",
      "845 310\n",
      "822 286\n",
      "801 242\n",
      "790 221\n",
      "786 189\n",
      "782 173\n",
      "780 153\n",
      "777 116\n",
      "776 86\n",
      "783 78\n",
      "781 62\n",
      "777 59\n",
      "780 58\n",
      "776 62\n",
      "766 54\n",
      "752 48\n",
      "748 36\n",
      "742 34\n",
      "730 34\n",
      "721 27\n",
      "712 31\n",
      "637 37\n",
      "626 33\n",
      "627 30\n",
      "674 30\n",
      "717 28\n",
      "736 33\n",
      "742 28\n",
      "732 30\n",
      "723 36\n",
      "735 46\n",
      "742 44\n",
      "741 46\n",
      "750 42\n",
      "720 58\n",
      "631 53\n",
      "610 38\n",
      "580 34\n",
      "581 38\n",
      "571 26\n",
      "554 27\n",
      "540 23\n",
      "548 29\n",
      "556 37\n",
      "572 52\n",
      "811 553\n",
      "833 565\n",
      "840 554\n",
      "845 539\n",
      "829 522\n",
      "840 523\n",
      "844 523\n",
      "883 571\n",
      "912 621\n",
      "953 699\n",
      "975 737\n",
      "968 727\n",
      "973 732\n",
      "976 757\n",
      "963 731\n",
      "966 720\n",
      "969 722\n",
      "969 720\n",
      "970 754\n",
      "948 735\n",
      "957 743\n",
      "981 746\n",
      "1007 731\n",
      "1005 733\n",
      "1002 758\n",
      "1007 754\n",
      "1007 759\n",
      "1012 763\n",
      "1033 785\n",
      "1039 798\n",
      "1042 802\n",
      "1025 797\n",
      "1017 798\n",
      "1007 781\n",
      "1006 795\n",
      "1070 891\n",
      "963 737\n",
      "1007 780\n",
      "946 702\n",
      "964 714\n",
      "998 738\n",
      "1086 760\n",
      "947 367\n",
      "956 379\n",
      "977 384\n"
     ]
    }
   ],
   "source": [
    "#Using your index finger (Fold your index finger) for a double click\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "\n",
    "def main():\n",
    "    # For webcam input:\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    screen_width, screen_height = pyautogui.size()\n",
    "\n",
    "    with mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Ignoring empty camera frame.\")\n",
    "                # If loading a video, use 'break' instead of 'continue'.\n",
    "                continue\n",
    "\n",
    "            # Flip the image horizontally for a later selfie-view display, and convert\n",
    "            # the BGR image to RGB.\n",
    "            frame = cv2.cvtColor(cv2.flip(frame, 1), cv2.COLOR_BGR2RGB)\n",
    "            # To improve performance, optionally mark the image as not writeable to\n",
    "            # pass by reference.\n",
    "            frame.flags.writeable = False\n",
    "            results = hands.process(frame)\n",
    "\n",
    "            # Draw the hand annotations on the image.\n",
    "            frame.flags.writeable = True\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "            if results.multi_hand_landmarks:\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                    # Adjust the coordinates (x, y) of the index finger tip to match the image captured by the camera\n",
    "                    index_finger_tip_x = int(hand_landmarks.landmark[8].x * screen_width)\n",
    "                    index_finger_tip_y = int(hand_landmarks.landmark[8].y * screen_height)\n",
    "\n",
    "                   # Adjust the coordinates (x, y) of the second joint of the index finger to match the image captured by the camera\n",
    "                    index_finger_pip_x = int(hand_landmarks.landmark[6].x * screen_width)\n",
    "                    index_finger_pip_y = int(hand_landmarks.landmark[6].y * screen_height)\n",
    "\n",
    "                    # Perform a double-click when the index finger is bent\n",
    "                    if index_finger_tip_y > index_finger_pip_y:\n",
    "                        pyautogui.doubleClick(index_finger_pip_x, index_finger_pip_y)\n",
    "\n",
    "                    # Otherwise, move the cursor\n",
    "                    else:\n",
    "                        print(index_finger_pip_x, index_finger_pip_y)\n",
    "                        pyautogui.moveTo(index_finger_pip_x, index_finger_pip_y)\n",
    "\n",
    "            cv2.imshow(\"Hand Detection\", frame)\n",
    "\n",
    "            if cv2.waitKey(5) & 0xFF == 27:\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4606574",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81d2cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using you index finger and middle finger to click or unclick(Single clicks)\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "\n",
    "def main():\n",
    "    # For webcam input:\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    screen_width, screen_height = pyautogui.size()\n",
    "\n",
    "    with mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Ignoring empty camera frame.\")\n",
    "                continue\n",
    "\n",
    "            frame = cv2.cvtColor(cv2.flip(frame, 1), cv2.COLOR_BGR2RGB)\n",
    "            frame.flags.writeable = False\n",
    "            results = hands.process(frame)\n",
    "\n",
    "            frame.flags.writeable = True\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "            if results.multi_hand_landmarks:\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                    # Get the coordinates (x, y) of the index and middle finger tips\n",
    "                    index_finger_tip = hand_landmarks.landmark[8]\n",
    "                    middle_finger_tip = hand_landmarks.landmark[12]\n",
    "\n",
    "                    index_finger_tip_x = int(index_finger_tip.x * screen_width)\n",
    "                    index_finger_tip_y = int(index_finger_tip.y * screen_height)\n",
    "                    middle_finger_tip_x = int(middle_finger_tip.x * screen_width)\n",
    "                    middle_finger_tip_y = int(middle_finger_tip.y * screen_height)\n",
    "\n",
    "                    # Check if both index and middle fingers are close together to simulate a click action\n",
    "                    distance_threshold = 100  # Adjust this threshold as needed\n",
    "                    if (\n",
    "                        abs(index_finger_tip_x - middle_finger_tip_x) < distance_threshold\n",
    "                        and abs(index_finger_tip_y - middle_finger_tip_y) < distance_threshold\n",
    "                    ):\n",
    "                        pyautogui.click()\n",
    "\n",
    "                    # Otherwise, move the cursor\n",
    "                    else:\n",
    "                        pyautogui.moveTo(index_finger_tip_x, index_finger_tip_y)\n",
    "\n",
    "            cv2.imshow(\"Hand Detection\", frame)\n",
    "\n",
    "            if cv2.waitKey(5) & 0xFF == 27:\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6d2bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#An attempt to use both of the above codes basic features combined, goes unresponsive or won't open the windows\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "def main():\n",
    "    # For webcam input:\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    screen_width, screen_height = pyautogui.size()\n",
    "    \n",
    "    # Initialize the previous state of the index finger\n",
    "    prev_index_finger_folded = False\n",
    "\n",
    "    with mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Ignoring empty camera frame.\")\n",
    "                continue\n",
    "\n",
    "            frame = cv2.cvtColor(cv2.flip(frame, 1), cv2.COLOR_BGR2RGB)\n",
    "            frame.flags.writeable = False\n",
    "            results = hands.process(frame)\n",
    "\n",
    "            frame.flags.writeable = True\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "            if results.multi_hand_landmarks:\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                    # Get the coordinates (x, y) of the index and middle finger tips\n",
    "                    index_finger_tip = hand_landmarks.landmark[8]\n",
    "                    middle_finger_tip = hand_landmarks.landmark[12]\n",
    "\n",
    "                    index_finger_tip_x = int(index_finger_tip.x * screen_width)\n",
    "                    index_finger_tip_y = int(index_finger_tip.y * screen_height)\n",
    "                    middle_finger_tip_x = int(middle_finger_tip.x * screen_width)\n",
    "                    middle_finger_tip_y = int(middle_finger_tip.y * screen_height)\n",
    "\n",
    "                    # Calculate the Euclidean distance between the index and middle finger tips\n",
    "                    distance = ((index_finger_tip_x - middle_finger_tip_x) ** 2 + (index_finger_tip_y - middle_finger_tip_y) ** 2) ** 0.5\n",
    "\n",
    "                    # Check if the index finger is folded (distance is smaller than a threshold)\n",
    "                    index_finger_folded = distance < 30  # Adjust this threshold as needed\n",
    "\n",
    "                    if index_finger_folded:\n",
    "                        # If the index finger is folded, perform a single click\n",
    "                        pyautogui.click()\n",
    "\n",
    "                    # Otherwise, move the cursor\n",
    "                    else:\n",
    "                        pyautogui.moveTo(index_finger_tip_x, index_finger_tip_y)\n",
    "\n",
    "                    # Store the current state of the index finger for the next iteration\n",
    "                    prev_index_finger_folded = index_finger_folded\n",
    "\n",
    "            cv2.imshow(\"Hand Detection\", frame)\n",
    "\n",
    "            if cv2.waitKey(5) & 0xFF == 27:\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8a681d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
